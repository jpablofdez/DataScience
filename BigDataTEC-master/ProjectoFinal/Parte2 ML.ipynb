{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BigData\n",
    "\n",
    "Proyecto Final\n",
    "\n",
    "Juan Pablo Fernández Deltado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARTE II - Machine Learning con datos en PostgreSQL:\n",
    " \n",
    "Seleccionar un set de datos de su preferencia, que no corresponda a un conjunto trivial, haciendo uso de PostgreSQL y la librería MLlib llevar a cabo un análisis predictivo o clasificatorio, que resuelva algún problema en el conjunto de datos seleccionado.\n",
    "El analisis de los datos se hizon con el set de datos del titanic.\n",
    "\n",
    "Tabla en postgres\n",
    "\n",
    "-- DROP TABLE public.titanic;\n",
    "\n",
    "CREATE TABLE public.titanic\n",
    "(\n",
    "    passengerid integer,\n",
    "    survived integer,\n",
    "    pclass integer,\n",
    "    \"Name\" text COLLATE pg_catalog.\"default\",\n",
    "    sex text COLLATE pg_catalog.\"default\",\n",
    "    age integer,\n",
    "    sibsp integer,\n",
    "    parch integer,\n",
    "    ticket text COLLATE pg_catalog.\"default\",\n",
    "    fare integer,\n",
    "    cabin text COLLATE pg_catalog.\"default\",\n",
    "    embarked text COLLATE pg_catalog.\"default\"\n",
    ")\n",
    "WITH (\n",
    "    OIDS = FALSE\n",
    ")\n",
    "TABLESPACE pg_default;\n",
    "\n",
    "ALTER TABLE public.titanic\n",
    "    OWNER to postgres;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: Para realizar la conexión con la base de datos se agrego el driver de conexión de postgre en la siguiente ruta:\n",
    "C:\\Spark\\jars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el spark session object, llamarle \"supervised_ml\"\n",
    "spark=SparkSession.builder.appName('supervised_ml').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias de pyspark\n",
    "import findspark\n",
    "findspark.init('C:\\Spark')\n",
    "\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, date_format, udf \n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "# Importacion de libs y operaciones\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuracion del driver de conexión de postgres\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Basic JDBC pipeline\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"C:/Users/JuanPablo/BigDataTEC-master/Projecto/postgresql-42.2.9.jar\") \\\n",
    "    .config(\"spark.executor.extraClassPath\", \"C:/Users/JuanPablo/BigDataTEC-master/Projecto/postgresql-42.2.9.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+----+-----+--------+\n",
      "|passengerid|survived|pclass|                Name|   sex| age|sibsp|parch|          ticket|fare|cabin|embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+----+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|  22|    1|    0|       A/5 21171|   7| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|  38|    1|    0|        PC 17599|  71|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|  26|    0|    0|STON/O2. 3101282|   7| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|  35|    1|    0|          113803|  53| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|  35|    0|    0|          373450|   8| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877|   8| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|  54|    0|    0|           17463|  51|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|   2|    3|    1|          349909|  21| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|  27|    0|    2|          347742|  11| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|  14|    1|    0|          237736|  30| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|   4|    1|    1|         PP 9549|  16|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|  58|    0|    0|          113783|  26| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|  20|    0|    0|       A/5. 2151|   8| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|  39|    1|    5|          347082|  31| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|  14|    0|    0|          350406|   7| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|  55|    0|    0|          248706|  16| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|   2|    4|    1|          382652|  29| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|  13| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|  31|    1|    0|          345763|  18| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|   7| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+----+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parametros de conexión y lectura de tabla de la base de datos\n",
    "\n",
    "df = spark \\\n",
    "    .read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost/BigData\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"admin\") \\\n",
    "    .option(\"dbtable\", \"titanic\") \\\n",
    "    .load()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passengerid: integer (nullable = true)\n",
      " |-- survived: integer (nullable = true)\n",
      " |-- pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sibsp: integer (nullable = true)\n",
      " |-- parch: integer (nullable = true)\n",
      " |-- ticket: string (nullable = true)\n",
      " |-- fare: integer (nullable = true)\n",
      " |-- cabin: string (nullable = true)\n",
      " |-- embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+----+-----+--------+\n",
      "|passengerid|survived|pclass|                Name|   sex| age|sibsp|parch|          ticket|fare|cabin|embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+----+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|  22|    1|    0|       A/5 21171|   7| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|  38|    1|    0|        PC 17599|  71|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|  26|    0|    0|STON/O2. 3101282|   7| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|  35|    1|    0|          113803|  53| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|  35|    0|    0|          373450|   8| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877|   8| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|  54|    0|    0|           17463|  51|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|   2|    3|    1|          349909|  21| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|  27|    0|    2|          347742|  11| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|  14|    1|    0|          237736|  30| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+----+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# primeros 10 datos\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['passengerid',\n",
       " 'survived',\n",
       " 'pclass',\n",
       " 'Name',\n",
       " 'sex',\n",
       " 'age',\n",
       " 'sibsp',\n",
       " 'parch',\n",
       " 'ticket',\n",
       " 'fare',\n",
       " 'cabin',\n",
       " 'embarked']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = df.select(['Survived',\n",
    " 'Pclass',\n",
    " 'Sex',\n",
    " 'Age',\n",
    " 'SibSp',\n",
    " 'Parch',\n",
    " 'Fare',\n",
    " 'Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_final_data = my_cols.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajamos con datos categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n",
    "                                OneHotEncoder,StringIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_indexer = StringIndexer(inputCol='Sex',outputCol='SexIndex')\n",
    "gender_encoder = OneHotEncoder(inputCol='SexIndex',outputCol='SexVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "embark_indexer = StringIndexer(inputCol='Embarked',outputCol='EmbarkIndex')\n",
    "embark_encoder = OneHotEncoder(inputCol='EmbarkIndex',outputCol='EmbarkVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['age','sibsp','parch', 'fare']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uso de pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train Dataset : 515\n",
      "Size of test Dataset : 197\n"
     ]
    }
   ],
   "source": [
    "train, test = my_final_data.randomSplit([0.7,.3])\n",
    "\n",
    "\n",
    "print(f\"Size of train Dataset : {train.count()}\" )\n",
    "print(f\"Size of test Dataset : {test.count()}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = LinearRegression(featuresCol='features',labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_ln = Pipeline(stages=[gender_indexer,embark_indexer,\n",
    "                           gender_encoder,embark_encoder,\n",
    "                           assembler,ln])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model_ln = pipeline_ln.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionRN = fit_model_ln.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+---+-----+-----+----+--------+--------+-----------+-------------+-------------+--------------------+-------------------+\n",
      "|Survived|Pclass|   Sex|Age|SibSp|Parch|Fare|Embarked|SexIndex|EmbarkIndex|       SexVec|    EmbarkVec|            features|         prediction|\n",
      "+--------+------+------+---+-----+-----+----+--------+--------+-----------+-------------+-------------+--------------------+-------------------+\n",
      "|       0|     1|female|  2|    1|    2| 151|       S|     1.0|        0.0|    (1,[],[])|(2,[0],[1.0])|[1.0,0.0,2.0,1.0,...|  1.131407282317133|\n",
      "|       0|     1|female| 50|    0|    0|  28|       C|     1.0|        1.0|    (1,[],[])|(2,[1],[1.0])|(8,[0,2,5,7],[1.0...| 0.9131422850758324|\n",
      "|       0|     1|  male| 18|    1|    0| 108|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,18.0,1.0...|  0.644042424666612|\n",
      "|       0|     1|  male| 19|    3|    2| 263|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,19.0,3.0...|0.40340751596188673|\n",
      "|       0|     1|  male| 21|    0|    1|  77|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,21.0,0.0...| 0.5914912669038905|\n",
      "|       0|     1|  male| 22|    0|    0| 135|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,22.0,0.0...| 0.6944346754541765|\n",
      "|       0|     1|  male| 24|    0|    0|  79|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,24.0,0.0...| 0.6676805637986138|\n",
      "|       0|     1|  male| 27|    0|    2| 211|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,27.0,0.0...|  0.650299072639789|\n",
      "|       0|     1|  male| 28|    1|    0|  82|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,28.0,1.0...| 0.5597345890999739|\n",
      "|       0|     1|  male| 31|    1|    0|  52|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,31.0,1.0...| 0.4402024310147731|\n",
      "+--------+------+------+---+-----+-----+----+--------+--------+-----------+-------------+-------------+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visulizacion \n",
    "predictionRN.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Logistica is 0.3512060488599934\n"
     ]
    }
   ],
   "source": [
    "# valor de R2\n",
    "ln_evaluator = RegressionEvaluator(labelCol='Survived', metricName='r2')\n",
    "ln_r2 = lr_evaluator.evaluate(predictionRN)\n",
    "\n",
    "print(f'Regression Logistica is {ln_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.020397208803005773\n"
     ]
    }
   ],
   "source": [
    "# valor del meanSquaredError\n",
    "\n",
    "lr_rmse = lr_evaluator.evaluate(predictionRL)\n",
    "print(f'RMSE {lr_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|Survived|         prediction|\n",
      "+--------+-------------------+\n",
      "|       0|  1.131407282317133|\n",
      "|       0| 0.9131422850758324|\n",
      "|       0|  0.644042424666612|\n",
      "|       0|0.40340751596188673|\n",
      "|       0| 0.5914912669038905|\n",
      "|       0| 0.6944346754541765|\n",
      "|       0| 0.6676805637986138|\n",
      "|       0|  0.650299072639789|\n",
      "|       0| 0.5597345890999739|\n",
      "|       0| 0.4402024310147731|\n",
      "|       0|0.47157510892046073|\n",
      "|       0| 0.4355882455192642|\n",
      "|       0| 0.4010289977585272|\n",
      "|       0|  0.323087963846455|\n",
      "|       0|0.38751687486028696|\n",
      "|       0| 0.3891167003011756|\n",
      "|       0| 0.2902216641864499|\n",
      "|       0| 0.3299836835836648|\n",
      "|       0|0.26631296998750154|\n",
      "|       0|0.32961541463924393|\n",
      "+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionRN.select('Survived','prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion Logistica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='features',labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[gender_indexer,embark_indexer,\n",
    "                           gender_encoder,embark_encoder,\n",
    "                           assembler,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionRL = fit_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+---+-----+-----+----+--------+--------+-----------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "|Survived|Pclass|   Sex|Age|SibSp|Parch|Fare|Embarked|SexIndex|EmbarkIndex|       SexVec|    EmbarkVec|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+------+------+---+-----+-----+----+--------+--------+-----------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "|       0|     1|female| 25|    1|    2| 151|       S|     1.0|        0.0|    (1,[],[])|(2,[0],[1.0])|[1.0,0.0,25.0,1.0...|[-2.8558602408572...|[0.05437918325508...|       1.0|\n",
      "|       0|     1|  male| 18|    1|    0| 108|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,18.0,1.0...|[-0.8029421189372...|[0.30939652312014...|       1.0|\n",
      "|       0|     1|  male| 24|    0|    0|  79|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,24.0,0.0...|[-1.0117760790505...|[0.26663241311401...|       1.0|\n",
      "|       0|     1|  male| 27|    0|    2| 211|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,27.0,0.0...|[-1.3168927211927...|[0.21133572823156...|       1.0|\n",
      "|       0|     1|  male| 30|    0|    0|  27|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,30.0,0.0...|[-0.6376207621383...|[0.34578456720887...|       1.0|\n",
      "|       0|     1|  male| 31|    0|    0|  50|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,31.0,0.0...|[-0.0809224043611...|[0.47978043158399...|       1.0|\n",
      "|       0|     1|  male| 33|    0|    0|   5|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,33.0,0.0...|[0.11514078165797...|[0.52875343611521...|       0.0|\n",
      "|       0|     1|  male| 36|    1|    0|  78|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,36.0,1.0...|[0.57060316991392...|[0.63890234180651...|       0.0|\n",
      "|       0|     1|  male| 38|    0|    1| 153|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,38.0,0.0...|[-0.1088371357363...|[0.47281754330264...|       1.0|\n",
      "|       0|     1|  male| 50|    1|    0| 106|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,50.0,1.0...|[0.48254373517267...|[0.61834836060741...|       0.0|\n",
      "+--------+------+------+---+-----+-----+----+--------+--------+-----------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visulizacion \n",
    "predictionRL.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Lineal is 0.020397208803005773\n"
     ]
    }
   ],
   "source": [
    "# valor de R2\n",
    "lr_evaluator = RegressionEvaluator(labelCol='Survived', metricName='r2')\n",
    "lr_r2 = lr_evaluator.evaluate(predictionRL)\n",
    "\n",
    "print(f'Regression Logistica is {lr_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.020397208803005773\n"
     ]
    }
   ],
   "source": [
    "# valor del meanSquaredError\n",
    "\n",
    "lr_rmse = lr_evaluator.evaluate(predictionRL)\n",
    "print(f'RMSE {lr_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
    "                                       labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|Survived|prediction|\n",
      "+--------+----------+\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionRL.select('Survived','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = my_eval.evaluate(predictionRL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8427522349936137"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión con Árboles de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lib\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.classification import RandomForestClassifier,DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec_tree\n",
    "dec_tree = DecisionTreeClassifier(labelCol='Survived',featuresCol='features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: integer (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_final_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineTD = Pipeline(stages=[gender_indexer,embark_indexer,\n",
    "                           gender_encoder,embark_encoder,\n",
    "                           assembler,dec_tree])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model_DT = pipelineTD.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionDT = fit_model_DT.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+---+-----+-----+----+--------+--------+-----------+-------------+-------------+--------------------+-------------------+\n",
      "|Survived|Pclass|   Sex|Age|SibSp|Parch|Fare|Embarked|SexIndex|EmbarkIndex|       SexVec|    EmbarkVec|            features|         prediction|\n",
      "+--------+------+------+---+-----+-----+----+--------+--------+-----------+-------------+-------------+--------------------+-------------------+\n",
      "|       0|     1|female|  2|    1|    2| 151|       S|     1.0|        0.0|    (1,[],[])|(2,[0],[1.0])|[1.0,0.0,2.0,1.0,...|  1.131407282317133|\n",
      "|       0|     1|female| 50|    0|    0|  28|       C|     1.0|        1.0|    (1,[],[])|(2,[1],[1.0])|(8,[0,2,5,7],[1.0...| 0.9131422850758324|\n",
      "|       0|     1|  male| 18|    1|    0| 108|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,18.0,1.0...|  0.644042424666612|\n",
      "|       0|     1|  male| 19|    3|    2| 263|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,19.0,3.0...|0.40340751596188673|\n",
      "|       0|     1|  male| 21|    0|    1|  77|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,21.0,0.0...| 0.5914912669038905|\n",
      "|       0|     1|  male| 22|    0|    0| 135|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,22.0,0.0...| 0.6944346754541765|\n",
      "|       0|     1|  male| 24|    0|    0|  79|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,24.0,0.0...| 0.6676805637986138|\n",
      "|       0|     1|  male| 27|    0|    2| 211|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,27.0,0.0...|  0.650299072639789|\n",
      "|       0|     1|  male| 28|    1|    0|  82|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,28.0,1.0...| 0.5597345890999739|\n",
      "|       0|     1|  male| 31|    1|    0|  52|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,31.0,1.0...| 0.4402024310147731|\n",
      "+--------+------+------+---+-----+-----+----+--------+--------+-----------+-------------+-------------+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visulizacion \n",
    "predictionRL.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arbol de desicion is 0.09844614729672219\n"
     ]
    }
   ],
   "source": [
    "# valor de R2\n",
    "dt_evaluator = RegressionEvaluator(labelCol='Survived', metricName='r2')\n",
    "dt_r2 = dt_evaluator.evaluate(predictionDT)\n",
    "\n",
    "print(f'Arbol de desicion is {dt_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.09844614729672219\n"
     ]
    }
   ],
   "source": [
    "# valor del meanSquaredError\n",
    "\n",
    "dt_rmse = dt_evaluator.evaluate(predictionDT)\n",
    "print(f'RMSE {dt_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = my_eval.evaluate(predictionDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7774052788420605"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"Survived\", featuresCol=\"features\", numTrees=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineRF = Pipeline(stages=[gender_indexer,embark_indexer,\n",
    "                           gender_encoder,embark_encoder,\n",
    "                           assembler,rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model_RF = pipelineRF.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionRF = fit_model_RF.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: integer (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- SexIndex: double (nullable = false)\n",
      " |-- EmbarkIndex: double (nullable = false)\n",
      " |-- SexVec: vector (nullable = true)\n",
      " |-- EmbarkVec: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionRF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       1.0|       0|[1.0,0.0,2.0,1.0,...|\n",
      "|       1.0|       0|(8,[0,2,5,7],[1.0...|\n",
      "|       1.0|       0|[1.0,1.0,18.0,1.0...|\n",
      "|       0.0|       0|[1.0,1.0,19.0,3.0...|\n",
      "|       0.0|       0|[1.0,1.0,21.0,0.0...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionRF.select(\"prediction\", \"Survived\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomw Forest 0.09844614729672219\n"
     ]
    }
   ],
   "source": [
    "# valor de R2\n",
    "rf_evaluator = RegressionEvaluator(labelCol='Survived', metricName='r2')\n",
    "rf_r2 = rf_evaluator.evaluate(predictionRF)\n",
    "\n",
    "print(f'Randomw Forest {rf_r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.09844614729672219\n"
     ]
    }
   ],
   "source": [
    "# valor del meanSquaredError\n",
    "\n",
    "rf_rmse = rf_evaluator.evaluate(predictionRF)\n",
    "print(f'RMSE {rf_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = my_eval.evaluate(predictionRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7587803320561943"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
